# -*- coding: utf-8 -*-
"""DETR_train

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s8FwyyfLsJaKkXxlwf12MdG4e5rCnihl
"""
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('--input_path', type=str, default='./drive/MyDrive/CVPDL/HW1/train', help='source of train')
parser.add_argument('--valid_path', type=str, default='./drive/MyDrive/CVPDL/HW1/valid', help='source of valid')
config = parser.parse_known_args()[0]
model_checkpoint = "facebook/detr-resnet-50" # pre-trained model from which to fine-tune
input_path = config.input_path
valid_path = config.valid_path
"""#transform data"""

import json
from collections import defaultdict
#設置categoryid2label
id2label = defaultdict()
label2id = defaultdict()
train_del_list=[]
# 讀取JSON檔案
with open(input_path+'/_annotations.coco.json', 'r') as f:
    data = json.load(f)
with open(input_path+"/metadata.jsonl", "w") as outfile:
  # 從dict中取出需要的資料
  categories = data['categories']
  annotation_data = data['annotations']
  image_data = data['images']
  #取出file name and id
  name2idx=defaultdict()
  metadata=defaultdict()
  #完成cat_id2label
  for cat in categories:
    id2label[cat['id']] = cat['name']
  #生成data
  for img in image_data:
    name2idx[img['id']] = img['file_name']
    metadata[img['id']] ={"image_id":img['id'],"file_name":img['file_name'],"width":img["width"],"height":img["height"],"objects":{"id":[],"area":[],"bbox":[],"category":[]}}
  #取出bbox and category
  for ann in annotation_data:
    img_id = ann['image_id']
    width = metadata[img_id]['width']
    height = metadata[img_id]['height']
    category = ann['category_id']
    bbox = ann['bbox']
    metadata[img_id]['objects']['id'].append(ann['id'])
    metadata[img_id]['objects']['area'].append(ann['area'])
    metadata[img_id]['objects']['bbox'].append(bbox)
    metadata[img_id]['objects']['category'].append(category)
  for k,v in metadata.items():
    bboxes = v['objects']['bbox']
    if len(bboxes)==0:
      train_del_list.append(k)
  for k in train_del_list:
    print('delete'+str(k))
  #寫入新metadata
  for k,v in metadata.items():
    json.dump(v,outfile)
    outfile.write("\n")
for k,v in id2label.items():
  label2id[v]=k
# 讀取JSON檔案
with open(valid_path+'/_annotations.coco.json', 'r') as f:
    data = json.load(f)
with open(valid_path+"/metadata.jsonl", "w") as outfile:
  # 從dict中取出需要的資料
  annotation_data = data['annotations']
  image_data = data['images']
  #取出file name and id
  name2idx=defaultdict()
  metadata=defaultdict()
  valid_del_list=[]
  #生成data
  for img in image_data:
    name2idx[img['id']] = img['file_name']
    metadata[img['id']] ={"image_id":img['id'],"file_name":img['file_name'],"width":img["width"],"height":img["height"],"objects":{"id":[],"area":[],"bbox":[],"category":[]}}
  #取出bbox and category
  for ann in annotation_data:
    img_id = ann['image_id']
    category = ann['category_id']
    width = metadata[img_id]['width']
    height = metadata[img_id]['height']
    bbox = ann['bbox']
    metadata[img_id]['objects']['id'].append(ann['id'])
    metadata[img_id]['objects']['area'].append(ann['area'])
    metadata[img_id]['objects']['bbox'].append(bbox)
    metadata[img_id]['objects']['category'].append(category)
  for k,v in metadata.items():
    bboxes = v['objects']['bbox']
    if len(bboxes)==0:

      valid_del_list.append(k)
  for k in valid_del_list:
    print('delete'+str(k))
  #寫入新metadata
  for k,v in metadata.items():
    json.dump(v,outfile)
    outfile.write("\n")

from datasets import load_dataset 

train_dataset = load_dataset(input_path)
valid_dataset = load_dataset(valid_path)
train_dataset['valid'] = valid_dataset['train']
dataset = train_dataset

dataset['train'] = dataset['train'].select(
    (
        i for i in range(len(dataset['train'])) 
        if i not in set(train_del_list)
    )
)
dataset['valid'] = dataset['valid'].select(
    (
        i for i in range(len(dataset['valid'])) 
        if i not in set(valid_del_list)
    )
)

"""# Preprocessing the data"""

from transformers import AutoImageProcessor
import albumentations
import numpy as np
import torch

# transforming a batch
def formatted_anns(image_id, category, area, bbox):
    annotations = []
    for i in range(0, len(category)):
        new_ann = {
            "image_id": image_id,
            "category_id": category[i],
            "isCrowd": 0,
            "area": area[i],
            "bbox": list(bbox[i]),
        }
        annotations.append(new_ann)

    return annotations
def transform_aug_ann(examples):
    image_ids = examples["image_id"]
    images, bboxes, area, categories = [], [], [], []
    for image, objects in zip(examples["image"], examples["objects"]):
        image = np.array(image.convert("RGB"))
        out = transform(image=image, bboxes=objects["bbox"], category=objects["category"])

        area.append(objects["area"])
        images.append(out["image"])
        bboxes.append(out["bboxes"])
        categories.append(out["category"])

    targets = [
        {"image_id": id_, "annotations": formatted_anns(id_, cat_, ar_, box_)}
        for id_, cat_, ar_, box_ in zip(image_ids, categories, area, bboxes)
    ]

    return image_processor(images=images, annotations=targets, return_tensors="pt")
    
def transform_ann(examples):
  images, bboxes, area, categories = [], [], [], []
  image_ids = examples["image_id"]
  for image,objects in zip(examples["image"],examples["objects"]):
    image = np.array(image.convert("RGB"))
    area.append(objects["area"])
    images.append(image)
    bboxes.append(objects["bbox"])
    categories.append(objects["category"])
  targets = [
    {"image_id": id_, "annotations": formatted_anns(id_, cat_, ar_, box_)}
    for id_, cat_, ar_, box_ in zip(image_ids, categories, area, bboxes)
  ]



  return image_processor(images=images, annotations=targets, return_tensors="pt")
  
def collate_fn(batch):
    pixel_values = [item["pixel_values"] for item in batch]
    encoding = image_processor.pad_and_create_pixel_mask(pixel_values, return_tensors="pt")
    labels = [item["labels"] for item in batch]
    batch = {}
    batch["pixel_values"] = encoding["pixel_values"]
    batch["pixel_mask"] = encoding["pixel_mask"]
    batch["labels"] = labels
    return batch

checkpoint = "facebook/detr-resnet-50"
image_processor = AutoImageProcessor.from_pretrained(checkpoint)
transform = albumentations.Compose(
    [
        albumentations.Resize(480,480),
    ],
    bbox_params=albumentations.BboxParams(format="coco", label_fields=["category"]),
)
dataset["train"] = dataset["train"].with_transform(transform_aug_ann)
dataset["valid"] = dataset["valid"].with_transform(transform_aug_ann)

"""#Training"""

from transformers import AutoModelForObjectDetection
model = AutoModelForObjectDetection.from_pretrained(
    checkpoint,
    id2label=id2label,
    label2id=label2id,
    ignore_mismatched_sizes=True,
)

from transformers import TrainingArguments
training_args = TrainingArguments(
    output_dir="./detr-resnet-50_finetuned_cppe5",
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    evaluation_strategy="steps",
    eval_steps = 10,
    num_train_epochs=200,
    save_steps =50,
    logging_strategy="steps",
    logging_steps=10,
    learning_rate=1e-4,
    weight_decay=0,
    save_total_limit=2,
    remove_unused_columns=False,
    push_to_hub=False,
)

from transformers import Trainer

trainer = Trainer(
    model=model,
    args=training_args,
    data_collator=collate_fn,
    train_dataset=dataset["train"],
    eval_dataset=dataset["valid"],
    tokenizer=image_processor,
    
)
trainer.create_optimizer()
trainer.train()